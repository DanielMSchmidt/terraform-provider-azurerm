---
subcategory: "Stream Analytics"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_stream_analytics_output_table"
description: |-
  Manages a Stream Analytics Output Table.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_stream_analytics_output_table

Manages a Stream Analytics Output Table.

## Example Usage

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.azurerm as azurerm
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        azurerm_resource_group_example = azurerm.resource_group.ResourceGroup(self, "example",
            location="West Europe",
            name="rg-example"
        )
        azurerm_storage_account_example =
        azurerm.storage_account.StorageAccount(self, "example_1",
            account_replication_type="LRS",
            account_tier="Standard",
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="examplesa",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_account_example.override_logical_id("example")
        azurerm_storage_table_example = azurerm.storage_table.StorageTable(self, "example_2",
            name="exampletable",
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_table_example.override_logical_id("example")
        data_azurerm_stream_analytics_job_example =
        azurerm.data_azurerm_stream_analytics_job.DataAzurermStreamAnalyticsJob(self, "example_3",
            name="example-job",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_azurerm_stream_analytics_job_example.override_logical_id("example")
        azurerm_stream_analytics_output_table_example =
        azurerm.stream_analytics_output_table.StreamAnalyticsOutputTable(self, "example_4",
            batch_size=100,
            name="output-to-storage-table",
            partition_key="foo",
            resource_group_name=cdktf.Token.as_string(data_azurerm_stream_analytics_job_example.resource_group_name),
            row_key="bar",
            storage_account_key=cdktf.Token.as_string(azurerm_storage_account_example.primary_access_key),
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name),
            stream_analytics_job_name=cdktf.Token.as_string(data_azurerm_stream_analytics_job_example.name),
            table=cdktf.Token.as_string(azurerm_storage_table_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_stream_analytics_output_table_example.override_logical_id("example")
```

## Arguments Reference

The following arguments are supported:

* `name` - (Required) The name of the Stream Output. Changing this forces a new resource to be created.

* `resource_group_name` - (Required) The name of the Resource Group where the Stream Analytics Job exists. Changing this forces a new resource to be created.

* `stream_analytics_job_name` - (Required) The name of the Stream Analytics Job. Changing this forces a new resource to be created.

* `storage_account_name` - (Required) The name of the Storage Account.

* `storage_account_key` - (Required) The Access Key which should be used to connect to this Storage Account.

* `table` - (Required) The name of the table where the stream should be output to.

* `partition_key` - (Required) The name of the output column that contains the partition key.

* `row_key` - (Required) The name of the output column that contains the row key.

* `batch_size` - (Required) The number of records for a batch operation. Must be between `1` and `100`.

* `columns_to_remove` - (Optional) A list of the column names to be removed from output event entities.

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The ID of the Stream Analytics Output Table.

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Stream Analytics.
* `read` - (Defaults to 5 minutes) Used when retrieving the Stream Analytics.
* `update` - (Defaults to 30 minutes) Used when updating the Stream Analytics.
* `delete` - (Defaults to 30 minutes) Used when deleting the Stream Analytics.

## Import

Stream Analytics Output to Table can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_stream_analytics_output_table.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.StreamAnalytics/streamingJobs/job1/outputs/output1
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-5209727fb5b54877f37a5877b9caf5810b3a7bcb9000863997d92431b0181eaf -->