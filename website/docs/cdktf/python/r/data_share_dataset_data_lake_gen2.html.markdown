---
subcategory: "Data Share"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_data_share_dataset_data_lake_gen2"
description: |-
  Manages a Data Share Data Lake Gen2 Dataset.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_data_share_dataset_data_lake_gen2

Manages a Data Share Data Lake Gen2 Dataset.

## Example Usage

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.azurerm as azurerm
import ...gen.providers.azuread as azuread
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # The following providers are missing schema information and might need manual adjustments to synthesize correctly: azuread.
        #     For a more precise conversion please use the --provider flag in convert.
        azurerm.provider.AzurermProvider(self, "azurerm",
            features=AzurermProviderFeatures()
        )
        azurerm_resource_group_example = azurerm.resource_group.ResourceGroup(self, "example",
            location="West Europe",
            name="example-resources"
        )
        azurerm_storage_account_example =
        azurerm.storage_account.StorageAccount(self, "example_2",
            account_kind="BlobStorage",
            account_replication_type="LRS",
            account_tier="Standard",
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="examplestr",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_account_example.override_logical_id("example")
        azurerm_storage_data_lake_gen2_filesystem_example =
        azurerm.storage_data_lake_gen2_filesystem.StorageDataLakeGen2Filesystem(self, "example_3",
            name="example-dlg2fs",
            storage_account_id=cdktf.Token.as_string(azurerm_storage_account_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_data_lake_gen2_filesystem_example.override_logical_id("example")
        azurerm_data_share_account_example =
        azurerm.data_share_account.DataShareAccount(self, "example_4",
            identity=DataShareAccountIdentity(
                type="SystemAssigned"
            ),
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="example-dsa",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_share_account_example.override_logical_id("example")
        data_azuread_service_principal_example =
        azuread.data_azuread_service_principal.DataAzureadServicePrincipal(self, "example_5",
            display_name=azurerm_data_share_account_example.name
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_azuread_service_principal_example.override_logical_id("example")
        azurerm_data_share_example = azurerm.data_share.DataShare(self, "example_6",
            account_id=cdktf.Token.as_string(azurerm_data_share_account_example.id),
            kind="CopyBased",
            name="example_ds"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_share_example.override_logical_id("example")
        azurerm_role_assignment_example =
        azurerm.role_assignment.RoleAssignment(self, "example_7",
            principal_id=cdktf.Token.as_string(data_azuread_service_principal_example.object_id),
            role_definition_name="Storage Blob Data Reader",
            scope=cdktf.Token.as_string(azurerm_storage_account_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_role_assignment_example.override_logical_id("example")
        azurerm_data_share_dataset_data_lake_gen2_example =
        azurerm.data_share_dataset_data_lake_gen2.DataShareDatasetDataLakeGen2(self, "example_8",
            depends_on=[azurerm_role_assignment_example],
            file_path="myfile.txt",
            file_system_name=cdktf.Token.as_string(azurerm_storage_data_lake_gen2_filesystem_example.name),
            name="accexample-dlg2ds",
            share_id=cdktf.Token.as_string(azurerm_data_share_example.id),
            storage_account_id=cdktf.Token.as_string(azurerm_storage_account_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_share_dataset_data_lake_gen2_example.override_logical_id("example")
```

## Arguments Reference

The following arguments are supported:

* `name` - (Required) The name which should be used for this Data Share Data Lake Gen2 Dataset. Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

* `share_id` - (Required) The resource ID of the Data Share where this Data Share Data Lake Gen2 Dataset should be created. Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

* `file_system_name` - (Required) The name of the data lake file system to be shared with the receiver. Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

* `storage_account_id` - (Required) The resource id of the storage account of the data lake file system to be shared with the receiver. Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

---

* `file_path` - (Optional) The path of the file in the data lake file system to be shared with the receiver. Conflicts with `folder_path` Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

* `folder_path` - (Optional) The folder path in the data lake file system to be shared with the receiver. Conflicts with `file_path` Changing this forces a new Data Share Data Lake Gen2 Dataset to be created.

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The resource ID of the Data Share Data Lake Gen2 Dataset.

* `display_name` - The name of the Data Share Dataset.

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Data Share Data Lake Gen2 Dataset.
* `read` - (Defaults to 5 minutes) Used when retrieving the Data Share Data Lake Gen2 Dataset.
* `delete` - (Defaults to 30 minutes) Used when deleting the Data Share Data Lake Gen2 Dataset.

## Import

Data Share Data Lake Gen2 Datasets can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_data_share_dataset_data_lake_gen2.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.DataShare/accounts/account1/shares/share1/dataSets/dataSet1
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-7f7480979120328b4f5404b14bd8f65fe995462007465716054af5ce3f8bdf9e -->