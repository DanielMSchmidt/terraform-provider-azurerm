---
subcategory: "Stream Analytics"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_stream_analytics_job_schedule"
description: |-
  Manages a Stream Analytics Job Schedule.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_stream_analytics_job_schedule

Manages a Stream Analytics Job Schedule.

## Example Usage

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.azurerm as azurerm
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        azurerm_resource_group_example = azurerm.resource_group.ResourceGroup(self, "example",
            location="West Europe",
            name="example-resources"
        )
        azurerm_storage_account_example =
        azurerm.storage_account.StorageAccount(self, "example_1",
            account_replication_type="LRS",
            account_tier="Standard",
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="example",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_account_example.override_logical_id("example")
        azurerm_storage_container_example =
        azurerm.storage_container.StorageContainer(self, "example_2",
            container_access_type="private",
            name="example",
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_container_example.override_logical_id("example")
        azurerm_stream_analytics_job_example =
        azurerm.stream_analytics_job.StreamAnalyticsJob(self, "example_3",
            compatibility_level="1.2",
            data_locale="en-GB",
            events_late_arrival_max_delay_in_seconds=60,
            events_out_of_order_max_delay_in_seconds=50,
            events_out_of_order_policy="Adjust",
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="example-job",
            output_error_policy="Drop",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name),
            streaming_units=3,
            tags={
                "environment": "Example"
            },
            transformation_query="    SELECT *\n    INTO [exampleoutput]\n    FROM [exampleinput]\n"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_stream_analytics_job_example.override_logical_id("example")
        azurerm_stream_analytics_output_blob_example =
        azurerm.stream_analytics_output_blob.StreamAnalyticsOutputBlob(self, "example_4",
            date_format="yyyy-MM-dd",
            name="exampleoutput",
            path_pattern="example-{date}-{time}",
            resource_group_name=cdktf.Token.as_string(azurerm_stream_analytics_job_example.resource_group_name),
            serialization=StreamAnalyticsOutputBlobSerialization(
                type="Avro"
            ),
            storage_account_key=cdktf.Token.as_string(azurerm_storage_account_example.primary_access_key),
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name),
            storage_container_name=cdktf.Token.as_string(azurerm_storage_container_example.name),
            stream_analytics_job_name=cdktf.Token.as_string(azurerm_stream_analytics_job_example.name),
            time_format="HH"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_stream_analytics_output_blob_example.override_logical_id("example")
        azurerm_stream_analytics_stream_input_blob_example =
        azurerm.stream_analytics_stream_input_blob.StreamAnalyticsStreamInputBlob(self, "example_5",
            date_format="yyyy/MM/dd",
            name="exampleinput",
            path_pattern="",
            resource_group_name=cdktf.Token.as_string(azurerm_stream_analytics_job_example.resource_group_name),
            serialization=StreamAnalyticsStreamInputBlobSerialization(
                encoding="UTF8",
                field_delimiter=",",
                type="Csv"
            ),
            storage_account_key=cdktf.Token.as_string(azurerm_storage_account_example.primary_access_key),
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name),
            storage_container_name=cdktf.Token.as_string(azurerm_storage_container_example.name),
            stream_analytics_job_name=cdktf.Token.as_string(azurerm_stream_analytics_job_example.name),
            time_format="HH"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_stream_analytics_stream_input_blob_example.override_logical_id("example")
        azurerm_storage_blob_example = azurerm.storage_blob.StorageBlob(self, "example_6",
            name="example",
            source="example.csv",
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name),
            storage_container_name=cdktf.Token.as_string(azurerm_storage_container_example.name),
            type="Block"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_blob_example.override_logical_id("example")
        azurerm_stream_analytics_job_schedule_example =
        azurerm.stream_analytics_job_schedule.StreamAnalyticsJobSchedule(self, "example_7",
            depends_on=[azurerm_stream_analytics_job_example, azurerm_stream_analytics_stream_input_blob_example, azurerm_stream_analytics_output_blob_example
            ],
            start_mode="CustomTime",
            start_time="2022-09-21T00:00:00Z",
            stream_analytics_job_id=cdktf.Token.as_string(azurerm_stream_analytics_job_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_stream_analytics_job_schedule_example.override_logical_id("example")
```

## Argument Reference

The following arguments are supported:

* `stream_analytics_job_id` - (Required) The ID of the Stream Analytics Job that should be scheduled or started. Changing this forces a new resource to be created.

* `start_mode` - (Required) The starting mode of the Stream Analytics Job. Possible values are `JobStartTime`, `CustomTime` and `LastOutputEventTime`.

-> **Note:** Setting `start_mode` to `LastOutputEventTime` is only possible if the job had been previously started and produced output.

* `start_time` - (Optional) The time in ISO8601 format at which the Stream Analytics Job should be started e.g. `2022-04-01T00:00:00Z`. This property can only be specified if `start_mode` is set to `CustomTime`

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The ID of the Stream Analytics Job.

* `last_output_time` - The time at which the Stream Analytics job last produced an output.

---

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Stream Analytics Job.
* `update` - (Defaults to 30 minutes) Used when updating the Stream Analytics Job.
* `read` - (Defaults to 5 minutes) Used when retrieving the Stream Analytics Job.
* `delete` - (Defaults to 30 minutes) Used when deleting the Stream Analytics Job.

## Import

Stream Analytics Job's can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_stream_analytics_job_schedule.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.StreamAnalytics/streamingJobs/job1/schedule/default
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-55138763c2ab0038c2e05ccd39891d5da895c0ae03d0ae4c6d96e592ed18ad2e -->