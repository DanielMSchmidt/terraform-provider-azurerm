---
subcategory: "Data Factory"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_data_factory_custom_dataset"
description: |-
  Manages a Dataset inside an Azure Data Factory. This is a generic resource that supports all different Dataset Types.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_data_factory_custom_dataset

Manages a Dataset inside an Azure Data Factory. This is a generic resource that supports all different Dataset Types.

## Example Usage

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.azurerm as azurerm
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        azurerm_resource_group_example = azurerm.resource_group.ResourceGroup(self, "example",
            location="West Europe",
            name="example-resources"
        )
        azurerm_storage_account_example =
        azurerm.storage_account.StorageAccount(self, "example_1",
            account_kind="BlobStorage",
            account_replication_type="LRS",
            account_tier="Standard",
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="example",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_account_example.override_logical_id("example")
        azurerm_storage_container_example =
        azurerm.storage_container.StorageContainer(self, "example_2",
            container_access_type="private",
            name="content",
            storage_account_name=cdktf.Token.as_string(azurerm_storage_account_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_storage_container_example.override_logical_id("example")
        azurerm_data_factory_example = azurerm.data_factory.DataFactory(self, "example_3",
            identity=DataFactoryIdentity(
                type="SystemAssigned"
            ),
            location=cdktf.Token.as_string(azurerm_resource_group_example.location),
            name="example",
            resource_group_name=cdktf.Token.as_string(azurerm_resource_group_example.name)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_factory_example.override_logical_id("example")
        azurerm_data_factory_linked_custom_service_example =
        azurerm.data_factory_linked_custom_service.DataFactoryLinkedCustomService(self, "example_4",
            data_factory_id=cdktf.Token.as_string(azurerm_data_factory_example.id),
            name="example",
            type="AzureBlobStorage",
            type_properties_json="{\n  \"connectionString\":\"${" + azurerm_storage_account_example.primary_connection_string + "}\"\n}\n"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_factory_linked_custom_service_example.override_logical_id("example")
        azurerm_data_factory_custom_dataset_example =
        azurerm.data_factory_custom_dataset.DataFactoryCustomDataset(self, "example_5",
            additional_properties={
                "bar": "test2",
                "foo": "test1"
            },
            annotations=["test1", "test2", "test3"],
            data_factory_id=cdktf.Token.as_string(azurerm_data_factory_example.id),
            description="test description",
            folder="testFolder",
            linked_service=DataFactoryCustomDatasetLinkedService(
                name=cdktf.Token.as_string(azurerm_data_factory_linked_custom_service_example.name),
                parameters={
                    "key1": "value1"
                }
            ),
            name="example",
            parameters={
                "Bar": "Test2",
                "foo": "test1"
            },
            schema_json="{\n  \"type\": \"object\",\n  \"properties\": {\n    \"name\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"firstName\": {\n          \"type\": \"string\"\n        },\n        \"lastName\": {\n          \"type\": \"string\"\n        }\n      }\n    },\n    \"age\": {\n      \"type\": \"integer\"\n    }\n  }\n}\n",
            type="Json",
            type_properties_json="{\n  \"location\": {\n    \"container\":\"${" + azurerm_storage_container_example.name + "}\",\n    \"fileName\":\"foo.txt\",\n    \"folderPath\": \"foo/bar/\",\n    \"type\":\"AzureBlobStorageLocation\"\n  },\n  \"encodingName\":\"UTF-8\"\n}\n"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        azurerm_data_factory_custom_dataset_example.override_logical_id("example")
```

## Argument Reference

* `name` - (Required) Specifies the name of the Data Factory Dataset. Changing this forces a new resource to be created. Must be globally unique. See the [Microsoft documentation](https://docs.microsoft.com/azure/data-factory/naming-rules) for all restrictions.

* `data_factory_id` - (Required) The Data Factory ID in which to associate the Dataset with. Changing this forces a new resource.

* `linked_service` - (Required) A `linked_service` block as defined below.

* `type` - (Required) The type of dataset that will be associated with Data Factory. Changing this forces a new resource to be created.

* `type_properties_json` - (Required) A JSON object that contains the properties of the Data Factory Dataset.

* `additional_properties` - (Optional) A map of additional properties to associate with the Data Factory Dataset.

* `annotations` - (Optional) List of tags that can be used for describing the Data Factory Dataset.

* `description` - (Optional) The description for the Data Factory Dataset.

* `folder` - (Optional) The folder that this Dataset is in. If not specified, the Dataset will appear at the root level.

* `parameters` - (Optional) A map of parameters to associate with the Data Factory Dataset.

* `schema_json` - (Optional) A JSON object that contains the schema of the Data Factory Dataset.

---

A `linked_service` block supports the following:

* `name` - (Required) The name of the Data Factory Linked Service.

* `parameters` - (Optional) A map of parameters to associate with the Data Factory Linked Service.

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The ID of the Data Factory Dataset.

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Data Factory Dataset.
* `update` - (Defaults to 30 minutes) Used when updating the Data Factory Dataset.
* `read` - (Defaults to 5 minutes) Used when retrieving the Data Factory Dataset.
* `delete` - (Defaults to 30 minutes) Used when deleting the Data Factory Dataset.

## Import

Data Factory Datasets can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_data_factory_custom_dataset.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/example/providers/Microsoft.DataFactory/factories/example/datasets/example
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-0bdaa6ad8274695fb1555a57e82a99c14d1732e2c5af22c1b77ff96056991a07 -->