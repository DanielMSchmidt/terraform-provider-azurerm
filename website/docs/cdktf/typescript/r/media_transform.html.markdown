---
subcategory: "Media"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_media_transform"
description: |-
  Manages a Transform.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_media_transform

Manages a Transform.

## Example Usage

```typescript
import * as constructs from "constructs";
import * as cdktf from "cdktf";
/*Provider bindings are generated by running cdktf get.
See https://cdk.tf/provider-generation for more details.*/
import * as azurerm from "./.gen/providers/azurerm";
class MyConvertedCode extends cdktf.TerraformStack {
  constructor(scope: constructs.Construct, name: string) {
    super(scope, name);
    const azurermResourceGroupExample = new azurerm.resourceGroup.ResourceGroup(
      this,
      "example",
      {
        location: "West Europe",
        name: "media-resources",
      }
    );
    const azurermStorageAccountExample =
      new azurerm.storageAccount.StorageAccount(this, "example_1", {
        accountReplicationType: "GRS",
        accountTier: "Standard",
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "examplestoracc",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStorageAccountExample.overrideLogicalId("example");
    const azurermMediaServicesAccountExample =
      new azurerm.mediaServicesAccount.MediaServicesAccount(this, "example_2", {
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "examplemediaacc",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
        storageAccount: [
          {
            id: cdktf.Token.asString(azurermStorageAccountExample.id),
            isPrimary: true,
          },
        ],
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermMediaServicesAccountExample.overrideLogicalId("example");
    const azurermMediaTransformExample =
      new azurerm.mediaTransform.MediaTransform(this, "example_3", {
        description: "My transform description",
        mediaServicesAccountName: cdktf.Token.asString(
          azurermMediaServicesAccountExample.name
        ),
        name: "transform1",
        output: [
          {
            builtinPreset: {
              presetName: "AACGoodQualityAudio",
            },
            onErrorAction: "ContinueJob",
            relativePriority: "Normal",
          },
        ],
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermMediaTransformExample.overrideLogicalId("example");
  }
}

```

## Example Usage with Multiple Outputs

```typescript
import * as constructs from "constructs";
import * as cdktf from "cdktf";
/*Provider bindings are generated by running cdktf get.
See https://cdk.tf/provider-generation for more details.*/
import * as azurerm from "./.gen/providers/azurerm";
class MyConvertedCode extends cdktf.TerraformStack {
  constructor(scope: constructs.Construct, name: string) {
    super(scope, name);
    const azurermResourceGroupExample = new azurerm.resourceGroup.ResourceGroup(
      this,
      "example",
      {
        location: "West Europe",
        name: "media-resources",
      }
    );
    const azurermStorageAccountExample =
      new azurerm.storageAccount.StorageAccount(this, "example_1", {
        accountReplicationType: "GRS",
        accountTier: "Standard",
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "examplestoracc",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStorageAccountExample.overrideLogicalId("example");
    const azurermMediaServicesAccountExample =
      new azurerm.mediaServicesAccount.MediaServicesAccount(this, "example_2", {
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "examplemediaacc",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
        storageAccount: [
          {
            id: cdktf.Token.asString(azurermStorageAccountExample.id),
            isPrimary: true,
          },
        ],
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermMediaServicesAccountExample.overrideLogicalId("example");
    const azurermMediaTransformExample =
      new azurerm.mediaTransform.MediaTransform(this, "example_3", {
        description: "My transform description",
        mediaServicesAccountName: cdktf.Token.asString(
          azurermMediaServicesAccountExample.name
        ),
        name: "transform1",
        output: [
          {
            builtinPreset: {
              presetConfiguration: {
                complexity: "Balanced",
                interleaveOutput: "NonInterleavedOutput",
                keyFrameIntervalInSeconds: 123122.5,
                maxBitrateBps: 300000,
                maxHeight: 480,
                maxLayers: 14,
                minBitrateBps: 200000,
                minHeight: 360,
              },
              presetName: "AACGoodQualityAudio",
            },
            onErrorAction: "ContinueJob",
            relativePriority: "Normal",
          },
          {
            audioAnalyzerPreset: {
              audioAnalysisMode: "Basic",
              audioLanguage: "en-US",
              experimentalOptions: {
                env: "test",
              },
            },
            onErrorAction: "ContinueJob",
            relativePriority: "Low",
          },
          {
            faceDetectorPreset: {
              analysisResolution: "StandardDefinition",
              blurType: "Med",
              experimentalOptions: {
                env: "test",
              },
              faceRedactorMode: "Combined",
            },
            onErrorAction: "StopProcessingJob",
            relativePriority: "Low",
          },
          {
            onErrorAction: "StopProcessingJob",
            relativePriority: "Normal",
            videoAnalyzerPreset: {
              audioAnalysisMode: "Basic",
              audioLanguage: "en-US",
              experimentalOptions: {
                env: "test",
              },
              insightsType: "AllInsights",
            },
          },
          {
            customPreset: {
              codec: [
                {
                  aacAudio: {
                    bitrate: 128000,
                    channels: 2,
                    profile: "AacLc",
                    samplingRate: 48000,
                  },
                },
                {
                  copyAudio: {
                    label: "test",
                  },
                },
                {
                  copyVideo: {
                    label: "test",
                  },
                },
                {
                  h264Video: {
                    complexity: "Quality",
                    keyFrameInterval: "PT1S",
                    layer: [
                      {
                        adaptiveBFrameEnabled: true,
                        bFrames: 3,
                        bitrate: 1045000,
                        bufferWindow: "PT5S",
                        crf: 23,
                        entropyMode: "Cabac",
                        height: "64",
                        level: "auto",
                        maxBitrate: 1045000,
                        profile: "Auto",
                        referenceFrames: 4,
                        slices: 0,
                        width: "64",
                      },
                      {
                        adaptiveBFrameEnabled: true,
                        bFrames: 3,
                        bitrate: 1000,
                        bufferWindow: "PT5S",
                        crf: 23,
                        entropyMode: "Cavlc",
                        frameRate: "32",
                        height: "64",
                        level: "auto",
                        maxBitrate: 1000,
                        profile: "High444",
                        referenceFrames: 4,
                        slices: 1,
                        width: "64",
                      },
                    ],
                    rateControlMode: "ABR",
                    sceneChangeDetectionEnabled: false,
                    stretchMode: "AutoSize",
                    syncMode: "Auto",
                  },
                },
                {
                  h265Video: {
                    complexity: "Speed",
                    keyFrameInterval: "PT2S",
                    layer: [
                      {
                        adaptiveBFrameEnabled: true,
                        bFrames: 3,
                        bitrate: 1045000,
                        bufferWindow: "PT5S",
                        crf: 23,
                        frameRate: "32",
                        height: "64",
                        label: "test",
                        level: "auto",
                        maxBitrate: 1045000,
                        profile: "Auto",
                        referenceFrames: 4,
                        slices: 5,
                        width: "64",
                      },
                    ],
                    sceneChangeDetectionEnabled: false,
                    stretchMode: "AutoSize",
                    syncMode: "Auto",
                  },
                },
                {
                  jpgImage: {
                    layer: [
                      {
                        height: "180",
                        label: "test",
                        quality: 70,
                        width: "120",
                      },
                    ],
                    range: "100%%",
                    spriteColumn: 1,
                    start: "10",
                    step: "10",
                    stretchMode: "AutoSize",
                    syncMode: "Auto",
                  },
                },
                {
                  pngImage: {
                    layer: [
                      {
                        height: "180",
                        label: "test",
                        width: "120",
                      },
                    ],
                    range: "80",
                    start: "{Best}",
                    step: "10",
                    stretchMode: "AutoSize",
                    syncMode: "Auto",
                  },
                },
              ],
              filter: {
                cropRectangle: {
                  height: "240",
                  left: "30",
                  top: "360",
                  width: "70",
                },
                deinterlace: {
                  mode: "AutoPixelAdaptive",
                  parity: "TopFieldFirst",
                },
                fadeIn: {
                  duration: "PT5S",
                  fadeColor: "0xFF0000",
                  start: "10",
                },
                fadeOut: {
                  duration: "90%%",
                  fadeColor: "#FF0C7B",
                  start: "10%%",
                },
                overlay: [
                  {
                    audio: {
                      audioGainLevel: 1,
                      end: "PT30S",
                      fadeInDuration: "PT1S",
                      fadeOutDuration: "PT2S",
                      inputLabel: "label.jpg",
                      start: "PT5S",
                    },
                  },
                  {
                    video: {
                      audioGainLevel: 1,
                      cropRectangle: {
                        height: "240",
                        left: "30",
                        top: "360",
                        width: "70",
                      },
                      end: "PT30S",
                      fadeInDuration: "PT1S",
                      fadeOutDuration: "PT2S",
                      inputLabel: "label.jpg",
                      opacity: 1,
                      position: {
                        height: "180",
                        left: "20",
                        top: "240",
                        width: "140",
                      },
                      start: "PT5S",
                    },
                  },
                ],
                rotation: "Auto",
              },
              format: [
                {
                  jpg: {
                    filenamePattern: "test{Basename}",
                  },
                },
                {
                  mp4: {
                    filenamePattern: "test{Bitrate}",
                    outputFile: [
                      {
                        labels: ["test", "ppe"],
                      },
                    ],
                  },
                },
                {
                  png: {
                    filenamePattern: "test{Basename}",
                  },
                },
                {
                  transportStream: {
                    filenamePattern: "test{Bitrate}",
                    outputFile: [
                      {
                        labels: ["prod"],
                      },
                    ],
                  },
                },
              ],
            },
            onErrorAction: "ContinueJob",
            relativePriority: "Low",
          },
        ],
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermMediaTransformExample.overrideLogicalId("example");
  }
}

```

## Arguments Reference

The following arguments are supported:

* `mediaServicesAccountName` - (Required) The Media Services account name. Changing this forces a new Transform to be created.

* `name` - (Required) The name which should be used for this Transform. Changing this forces a new Transform to be created.

* `resourceGroupName` - (Required) The name of the Resource Group where the Transform should exist. Changing this forces a new Transform to be created.

---

* `description` - (Optional) An optional verbose description of the Transform.

* `output` - (Optional) One or more `output` blocks as defined below. At least one `output` must be defined.

---

A `aacAudio` block supports the following:

* `bitrate` - (Optional) The bitrate of the audio in bits per second. Default to `128000`.

* `channels` - (Optional) The number of audio channels. Default to `2`.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `profile` - (Optional) The encoding profile to be used when encoding audio with AAC. Possible values are `aacLc`, `heAacV1`,and `heAacV2`. Default to `aacLc`.

* `samplingRate` - (Optional) The sampling rate to use for encoding in Hertz. Default to `48000`.

---

A `audioAnalyzerPreset` block supports the following:

* `audioLanguage` - (Optional) The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernible speech. If automatic detection fails to find the language, transcription would fall back to `enUs`. The list of supported languages is available here: <https://go.microsoft.com/fwlink/?linkid=2109463>.

* `audioAnalysisMode` - (Optional) Possible values are `basic` or `standard`. Determines the set of audio analysis operations to be performed. Default to `standard`.

* `experimentalOptions` - (Optional) Dictionary containing key value pairs for parameters not exposed in the preset itself.

---

An `audio` block supports the following:

* `inputLabel` - (Required) The label of the job input which is to be used as an overlay. The input must specify exact one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file.

* `audioGainLevel` - (Optional) The gain level of audio in the overlay. The value should be in the range `0` to `10`. The default is `10`.

* `end` - (Optional) The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, `pt30S` to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration.

* `fadeInDuration` - (Optional) The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as `pt0S`).

* `fadeOutDuration` - (Optional) The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as `pt0S`).

* `start` - (Optional) The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, `pt05S` to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video.

---

A `builtinPreset` block supports the following:

* `presetName` - (Required) The built-in preset to be used for encoding videos. The Possible values are `aacGoodQualityAudio`, `adaptiveStreaming`, `contentAwareEncoding`, `contentAwareEncodingExperimental`, `copyAllBitrateNonInterleaved`, `ddGoodQualityAudio`, `h265AdaptiveStreaming`, `h265ContentAwareEncoding`, `h265SingleBitrate4K`, `h265SingleBitrate1080P`, `h265SingleBitrate720P`, `h264MultipleBitrate1080P`, `h264MultipleBitrateSd`, `h264MultipleBitrate720P`, `h264SingleBitrate1080P`, `h264SingleBitrateSd` and `h264SingleBitrate720P`.

* `presetConfiguration` - (Optional) A `presentConfiguration` block as defined below.

---

A `codec` block supports the following:

* `aacAudio` - (Optional) A `aacAudio` block as defined above.
 
* `copyAudio` - (Optional) A `copyAudio` block as defined below.

* `copyVideo` - (Optional) A `copyVideo` block as defined below.

* `ddAudio` - (Optional) A `ddAudio` block as defined below.

* `h264Video` - (Optional) A `h264Video` block as defined below.

* `h265Video` - (Optional) A `h265Video` block as defined below.

* `jpgImage` - (Optional) A `jpgImage` block as defined below.

* `pngImage` - (Optional) A `pngImage` block as defined below.

-> **NOTE:** Each codec can only have one type: `aacAudio`, `copyAudio`, `copyVideo`, `ddAudio`, `h264Video`, `h265Video`, `jpgImage` or `pngImage`. If you need to apply different codec you must create one codec for each one.

---

A `copyAudio` block supports the following:

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior. 

---

A `copyVideo` block supports the following:

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior. 
 
---

A `cropRectangle` block supports the following:

* `height` - (Optional) The height of the rectangular region in pixels. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `left` - (Optional) The number of pixels from the left-margin. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `top` - (Optional) 	
  The number of pixels from the top-margin. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `width` - (Optional) The width of the rectangular region in pixels. This can be absolute pixel value (e.g` 100`), or relative to the size of the video (For example, `50%`).

---

A `customPreset` block supports the following:

* `codec` - (Required) One or more `codec` blocks as defined above.

* `format` - (Required) One or more `format` blocks as defined below.

* `experimentalOptions` - (Optional) Dictionary containing key value pairs for parameters not exposed in the preset itself.

* `filter` - (Optional) A `filter` block as defined below.
 
---

A `ddAudio` block supports the following:

* `bitrate` - (Optional) The bitrate of the audio in bits per second. Default to `192000`.

* `channels` - (Optional) The number of audio channels. Default to `2`.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `samplingRate` - (Optional) The sampling rate to use for encoding in Hertz. Default to `48000`.

---

A `deinterlace` block supports the following:

* `parity` - (Optional) The field parity to use for deinterlacing. Possible values are `auto`, `topFieldFirst` or `bottomFieldFirst`. Default to `auto`.

* `mode` - (Optional) The deinterlacing mode. Possible values are `autoPixelAdaptive` or `off`. Default to `autoPixelAdaptive`.

---

A `faceDetectorPreset` block supports the following:

* `analysisResolution` - (Optional) Possible values are `sourceResolution` or `standardDefinition`. Specifies the maximum resolution at which your video is analyzed. which will keep the input video at its original resolution when analyzed. Using `standardDefinition` will resize input videos to standard definition while preserving the appropriate aspect ratio. It will only resize if the video is of higher resolution. For example, a 1920x1080 input would be scaled to 640x360 before processing. Switching to `standardDefinition` will reduce the time it takes to process high resolution video. It may also reduce the cost of using this component (see <https://azure.microsoft.com/en-us/pricing/details/media-services/#analytics> for details). However, faces that end up being too small in the resized video may not be detected. Default to `sourceResolution`.

* `blurType` - (Optional) Specifies the type of blur to apply to faces in the output video. Possible values are `black`, `box`, `high`, `low`,and `med`.

* `experimentalOptions` - (Optional) Dictionary containing key value pairs for parameters not exposed in the preset itself.

* `faceRedactorMode` - (Optional) This mode provides the ability to choose between the following settings: 1) `analyze` - For detection only. This mode generates a metadata JSON file marking appearances of faces throughout the video. Where possible, appearances of the same person are assigned the same ID. 2) `combined` - Additionally redacts(blurs) detected faces. 3) `redact` - This enables a 2-pass process, allowing for selective redaction of a subset of detected faces. It takes in the metadata file from a prior analyze pass, along with the source video, and a user-selected subset of IDs that require redaction. Default to `analyze`.

---

A `fadeIn` block supports the following:

* `duration` - (Required) The duration of the fade effect in the video. The value can be in ISO 8601 format (For example, PT05S to fade In/Out a color during 5 seconds), or a frame count (For example, 10 to fade 10 frames from the start time), or a relative value to stream duration (For example, 10% to fade 10% of stream duration).

* `fadeColor` - (Required) 	
  The color for the fade in/out. It can be on the [CSS Level1 colors](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/color_keywords) or an RGB/hex value: e.g: `rgb(255,0,0)`, `0XFf0000` or `#ff0000`.

* `start` - (Optional) The position in the input video from where to start fade. The value can be in ISO 8601 format (For example, `pt05S` to start at 5 seconds), or a frame count (For example, `10` to start at the 10th frame), or a relative value to stream duration (For example, `10%` to start at 10% of stream duration). Default to `0`.

---

A `fadeOut` block supports the following:

* `duration` - (Required) The duration of the fade effect in the video. The value can be in ISO 8601 format (For example, PT05S to fade In/Out a color during 5 seconds), or a frame count (For example, 10 to fade 10 frames from the start time), or a relative value to stream duration (For example, 10% to fade 10% of stream duration).

* `fadeColor` - (Required) 	
  The color for the fade in/out. It can be on the [CSS Level1 colors](https://developer.mozilla.org/en-US/docs/Web/CSS/color_value/color_keywords) or an RGB/hex value: e.g: `rgb(255,0,0)`, `0XFf0000` or `#ff0000`.

* `start` - (Optional) The position in the input video from where to start fade. The value can be in ISO 8601 format (For example, `pt05S` to start at 5 seconds), or a frame count (For example, `10` to start at the 10th frame), or a relative value to stream duration (For example, `10%` to start at 10% of stream duration). Default to `0`.

---

A `filter` block supports the following:

* `cropRectangle` - (Optional) A `cropRectangle` block as defined above.

* `deinterlace` - (Optional) A `deinterlace` block as defined below.

* `fadeIn` - (Optional) A `fadeIn` block as defined above.

* `fadeOut` - (Optional) A `fadeOut` block as defined above.

* `overlay` - (Optional) One or more `overlay` blocks as defined below.

* `rotation` - (Optional) The rotation to be applied to the input video before it is encoded. Possible values are `auto`, `none`, `rotate90`, `rotate180`, `rotate270`,or `rotate0`. Default to `auto`.

---

A `format` block supports the following:

* `jpg` - (Optional) A `jpg` block as defined below.

* `mp4` - (Optional) A `mp4` block as defined below.

* `png` - (Optional) A `png` block as defined below.

* `transportStream` - (Optional) A `transportStream` block as defined below.
 
-> **NOTE:** Each format can only have one type: `jpg`, `mp4`, `png` or `transportStream`. If you need to apply different type you must create one format for each one.

---

A `h264Video` block supports the following:

* `complexity` - (Optional) The complexity of the encoding. Possible values are `balanced`, `speed` or `quality`. Default to `balanced`.

* `keyFrameInterval` - (Optional) The distance between two key frames. The value should be non-zero in the range `05` to `20` seconds, specified in ISO 8601 format. The default is `2` seconds (`pt2S`). Note that this setting is ignored if `syncMode` is set to `passthrough`, where the KeyFrameInterval value will follow the input source setting.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `layer` - (Optional) One or more `layer` blocks as defined below.

* `rateControlMode` - (Optional) The rate control mode. Possible values are `abr`, `cbr` or `crf`. Default to `abr`.

* `sceneChangeDetectionEnabled` - (Optional) Whether the encoder should insert key frames at scene changes. This flag should be set to true only when the encoder is being configured to produce a single output video. Default to `false`.

* `stretchMode` - (Optional) Specifies the resizing mode - how the input video will be resized to fit the desired output resolution(s). Possible values are `autoFit`, `autoSize` or `none`. Default to `autoSize`.

* `syncMode` - (Optional) Specifies the synchronization mode for the video. Possible values are `auto`, `cfr`, `passthrough` or `vfr`. Default to `auto`.

---

A `h265Video` block supports the following:

* `complexity` - (Optional) The complexity of the encoding. Possible values are `balanced`, `speed` or `quality`. Default to `balanced`.

* `keyFrameInterval` - (Optional) The distance between two key frames. The value should be non-zero in the range `05` to `20` seconds, specified in ISO 8601 format. The default is `2` seconds (`pt2S`). Note that this setting is ignored if `syncMode` is set to `passthrough`, where the KeyFrameInterval value will follow the input source setting.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `layer` - (Optional) One or more `layer` blocks as defined below.

* `sceneChangeDetectionEnabled` - (Optional) Whether the encoder should insert key frames at scene changes. This flag should be set to true only when the encoder is being configured to produce a single output video. Default to `false`.

* `stretchMode` - (Optional) Specifies the resizing mode - how the input video will be resized to fit the desired output resolution(s). Possible values are `autoFit`, `autoSize` or `none`. Default to `autoSize`.

* `syncMode` - (Optional) Specifies the synchronization mode for the video. Possible values are `auto`, `cfr`, `passthrough` or `vfr`. Default to `auto`.

---

A `jpg` block supports the following:

* `filenamePattern` - (Required) The file naming pattern used for the creation of output files. The following macros are supported in the file name: `{basename}` - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. `{extension}` - The appropriate extension for this format. `{label}` - The label assigned to the codec/layer. `{index}` - A unique index for thumbnails. Only applicable to thumbnails. `{audioStream}` - string "Audio" plus audio stream number(start from 1). `{bitrate}` - The audio/video bitrate in kbps. Not applicable to thumbnails. `{codec}` - The type of the audio/video codec. `{resolution}` - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.

---

A `jpgImage` block supports the following:

* `start` - (Required) The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, `pt05S` to start at 5 seconds), or a frame count (For example, `10` to start at the 10th frame), or a relative value to stream duration (For example, `10%` to start at 10% of stream duration). Also supports a macro `{best}`, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for `step` and `range`.

* `keyFrameInterval` - (Optional) The distance between two key frames. The value should be non-zero in the range `05` to `20` seconds, specified in ISO 8601 format. The default is `2` seconds (`pt2S`). Note that this setting is ignored if `syncMode` is set to `passthrough`, where the KeyFrameInterval value will follow the input source setting.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `layer` - (Optional) One or more `layer` blocks as defined below.

* `range` - (Optional) The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, `pt5M30S` to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, `300` to stop at the 300th frame from the frame at start time. If this value is `1`, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, `50%` to stop at half of stream duration from start time). The default value is `100%`, which means to stop at the end of the stream. 

* `spriteColumn` - (Optional) Sets the number of columns used in thumbnail sprite image. The number of rows are automatically calculated and a VTT file is generated with the coordinate mappings for each thumbnail in the sprite. Note: this value should be a positive integer and a proper value is recommended so that the output image resolution will not go beyond JPEG maximum pixel resolution limit `65535X65535`.

* `step` - (Optional) The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, `pt05S` for one image every 5 seconds), or a frame count (For example, `30` for one image every 30 frames), or a relative value to stream duration (For example, `10%` for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is `10%`, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at `1` if only one thumbnail is needed at start time.

* `stretchMode` - (Optional) The resizing mode, which indicates how the input video will be resized to fit the desired output resolution(s). Possible values are `autoFit`, `autoSize` or `none`. Default to `autoSize`.

* `syncMode` - (Optional) Specifies the synchronization mode for the video. Possible values are `auto`, `cfr`, `passthrough` or `vfr`. Default to `auto`.

---

A `layer` block within `h264Video` block supports the following:

* `bitrate` - (Required) The average bitrate in bits per second at which to encode the input video when generating this layer.

* `adaptiveBFrameEnabled` - (Optional) Whether adaptive B-frames are used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. Default to `true`.

* `bFrames` - (Optional) The number of B-frames to use when encoding this layer. If not specified, the encoder chooses an appropriate number based on the video profile and level.

* `bufferWindow` - (Optional) Specifies the maximum amount of time that the encoder should buffer frames before encoding. The value should be in ISO 8601 format. The value should be in the range `01` to `100` seconds. The default is `5` seconds (`pt5S`).

* `crf` - (Optional) The value of CRF to be used when encoding this layer. This setting takes effect when `rateControlMode` is set `crf`. The range of CRF value is between `0` and `51`, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default to `23`.

* `entropyMode` - (Optional) The entropy mode to be used for this layer. Possible values are `cabac` or `cavlc`. If not specified, the encoder chooses the mode that is appropriate for the profile and level.

* `frameRate` - (Optional) The frame rate (in frames per second) at which to encode this layer. The value can be in the form of `m/n` where `m` and `n` are integers (For example, `30000/1001`), or in the form of a number (For example, `30`, or `2997`). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video.

* `height` - (Optional) The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in height as the input.

* `label` - (Optional) The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.

* `level` - (Optional) The H.264 levels. Currently, the resource support Level up to `62`. The value can be `auto`, or a number that matches the H.264 profile. If not specified, the default is `auto`, which lets the encoder choose the Level that is appropriate for this layer.

* `maxBitrate` - (Optional) The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate.

* `profile` - (Optional) The H.264 profile. Possible values are `auto`, `baseline`, `high`, `high422`, `high444`,or `main`. Default to `auto`.

* `referenceFrames` - (Optional) The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.

* `slices` - (Optional) The number of slices to be used when encoding this layer. If not specified, default is `1`, which means that encoder will use a single slice for each frame.

* `width` - (Optional) The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in width as the input.

---

A `layer` block within `h265Video` block supports the following:

* `bitrate` - (Required) The average bitrate in bits per second at which to encode the input video when generating this layer.

* `adaptiveBFrameEnabled` - (Optional) Whether adaptive B-frames are used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. Default to `true`.

* `bFrames` - (Optional) The number of B-frames to use when encoding this layer. If not specified, the encoder chooses an appropriate number based on the video profile and level.

* `bufferWindow` - (Optional) Specifies the maximum amount of time that the encoder should buffer frames before encoding. The value should be in ISO 8601 format. The value should be in the range `01` to `100` seconds. The default is `5` seconds (`pt5S`).

* `crf` - (Optional) The value of CRF to be used when encoding this layer. This setting takes effect when `rateControlMode` is set `crf`. The range of CRF value is between `0` and `51`, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default to `28`.

* `entropyMode` - (Optional) The entropy mode to be used for this layer. Possible values are `cabac` or `cavlc`. If not specified, the encoder chooses the mode that is appropriate for the profile and level.

* `frameRate` - (Optional) 	
  The frame rate (in frames per second) at which to encode this layer. The value can be in the form of `m/n` where `m` and `n` are integers (For example, `30000/1001`), or in the form of a number (For example, `30`, or `2997`). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video.

* `height` - (Optional) The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in height as the input.

* `label` - (Optional) The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.

* `level` - (Optional) The H.264 levels. Currently, the resource support Level up to `62`. The value can be `auto`, or a number that matches the H.264 profile. If not specified, the default is `auto`, which lets the encoder choose the Level that is appropriate for this layer.

* `maxBitrate` - (Optional) The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate.

* `profile` - (Optional) The H.264 profile. Possible values are `auto`, `baseline`, `high`, `high422`, `high444`,or `main`. Default to `auto`.

* `referenceFrames` - (Optional) The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.

* `slices` - (Optional) The number of slices to be used when encoding this layer. If not specified, default is `1`, which means that encoder will use a single slice for each frame.

* `width` - (Optional) The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in width as the input.

---

A `layer` block within `jpgImage` block supports the following:

* `height` - (Optional) The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in height as the input.

* `label` - (Optional) The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.

* `quality` - (Optional) The compression quality of the JPEG output. Range is from `0` to `100` and the default is `70`.

* `width` - (Optional) The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in width as the input.

---

A `layer` block within `pngImage` block supports the following:

* `height` - (Optional) The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in height as the input.

* `label` - (Optional) The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.

* `width` - (Optional) The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example `50%` means the output video has half as many pixels in width as the input.

---

A `mp4` block supports the following:

* `filenamePattern` - (Required) The file naming pattern used for the creation of output files. The following macros are supported in the file name: `{basename}` - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. `{extension}` - The appropriate extension for this format. `{label}` - The label assigned to the codec/layer. `{index}` - A unique index for thumbnails. Only applicable to thumbnails. `{audioStream}` - string "Audio" plus audio stream number(start from 1). `{bitrate}` - The audio/video bitrate in kbps. Not applicable to thumbnails. `{codec}` - The type of the audio/video codec. `{resolution}` - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.

* `outputFile` - (Optional) One or more `outputFile` blocks as defined below.

---

An `output` block supports the following:

* `audioAnalyzerPreset` - (Optional) An `audioAnalyzerPreset` block as defined above.

* `builtinPreset` - (Optional) A `builtinPreset` block as defined above.

* `customPreset` - (Optional) A `customPreset` block as defined above.

* `faceDetectorPreset` - (Optional) A `faceDetectorPreset` block as defined above.

* `onErrorAction` - (Optional) A Transform can define more than one outputs. This property defines what the service should do when one output fails - either continue to produce other outputs, or, stop the other outputs. The overall Job state will not reflect failures of outputs that are specified with `continueJob`. Possible values are `stopProcessingJob` or `continueJob`. The default is `stopProcessingJob`.

* `relativePriority` - (Optional) Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing Transform Outputs. Possible values are `high`, `normal` or `low`. Defaults to `normal`.

* `videoAnalyzerPreset` - (Optional) A `videoAnalyzerPreset` block as defined below.

-> **NOTE:** Each output can only have one type of preset: `builtinPreset`, `audioAnalyzerPreset`, `customPreset`, `faceDetectorPreset` or `videoAnalyzerPreset`. If you need to apply different presets you must create one output for each one.

---

An `outputFile` block supports the following:

* `labels` - (Required) The list of labels that describe how the encoder should multiplex video and audio into an output file. For example, if the encoder is producing two video layers with labels `v1` and `v2`, and one audio layer with label `a1`, then an array like `["v1", "a1"]` tells the encoder to produce an output file with the video track represented by `v1` and the audio track represented by `a1`.

---

An `overlay` block supports the following:

* `audio` - (Optional) An `audio` block as defined above.

* `video` - (Optional) A `video` block as defined below.

-> **NOTE:** Each overlay can only have one type: `audio` or `video`. If you need to apply different type you must create one overlay for each one.

---

A `png` block supports the following:

* `filenamePattern` - (Required) The file naming pattern used for the creation of output files. The following macros are supported in the file name: `{basename}` - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. `{extension}` - The appropriate extension for this format. `{label}` - The label assigned to the codec/layer. `{index}` - A unique index for thumbnails. Only applicable to thumbnails. `{audioStream}` - string "Audio" plus audio stream number(start from 1). `{bitrate}` - The audio/video bitrate in kbps. Not applicable to thumbnails. `{codec}` - The type of the audio/video codec. `{resolution}` - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.

---

A `pngImage` block supports the following:

* `start` - (Required) The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, `pt05S` to start at 5 seconds), or a frame count (For example, `10` to start at the 10th frame), or a relative value to stream duration (For example, `10%` to start at 10% of stream duration). Also supports a macro `{best}`, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for `step` and `range`.

* `keyFrameInterval` - (Optional) The distance between two key frames. The value should be non-zero in the range `05` to `20` seconds, specified in ISO 8601 format. The default is `2` seconds (`pt2S`). Note that this setting is ignored if `syncMode` is set to `passthrough`, where the KeyFrameInterval value will follow the input source setting.

* `label` - (Optional) Specifies the label for the codec. The label can be used to control muxing behavior.

* `layer` - (Optional) One or more `layer` blocks as defined below.

* `range` - (Optional) The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, `pt5M30S` to stop at `5` minutes and `30` seconds from start time), or a frame count (For example, `300` to stop at the 300th frame from the frame at start time. If this value is `1`, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, `50%` to stop at half of stream duration from start time). The default value is `100%`, which means to stop at the end of the stream.

* `step` - (Optional) The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, `pt05S` for one image every 5 seconds), or a frame count (For example, `30` for one image every 30 frames), or a relative value to stream duration (For example, `10%` for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is `10%`, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at `1` if only one thumbnail is needed at start time.

* `stretchMode` - (Optional) The resizing mode, which indicates how the input video will be resized to fit the desired output resolution(s). Possible values are `autoFit`, `autoSize` or `none`. Default to `autoSize`.

* `syncMode` - (Optional) Specifies the synchronization mode for the video. Possible values are `auto`, `cfr`, `passthrough` or `vfr`. Default to `auto`.

---

A `position` block supports the following:

* `height` - (Optional) The height of the rectangular region in pixels. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `left` - (Optional) The number of pixels from the left-margin. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `top` - (Optional) 	
  The number of pixels from the top-margin. This can be absolute pixel value (e.g `100`), or relative to the size of the video (For example, `50%`).

* `width` - (Optional) The width of the rectangular region in pixels. This can be absolute pixel value (e.g` 100`), or relative to the size of the video (For example, `50%`).

---

A `presetConfiguration` block supports the following:

* `complexity` - (Optional) The complexity of the encoding. Possible values are `balanced`, `speed` or `quality`.

* `interleaveOutput` - (Optional) Specifies the interleave mode of the output to control how audio are stored in the container format. Possible values are `interleavedOutput` and `nonInterleavedOutput`. 

* `keyFrameIntervalInSeconds` - (Optional) The key frame interval in seconds. Possible value is a positive float. For example, set as `20` to reduce the playback buffering for some players.

* `maxBitrateBps` - (Optional) The maximum bitrate in bits per second (threshold for the top video layer). For example, set as `6000000` to avoid producing very high bitrate outputs for contents with high complexity.

* `maxHeight` - (Optional) The maximum height of output video layers. For example, set as `720` to produce output layers up to 720P even if the input is 4K.

* `maxLayers` - (Optional) The maximum number of output video layers. For example, set as `4` to make sure at most 4 output layers are produced to control the overall cost of the encoding job.

* `minBitrateBps` - (Optional) The minimum bitrate in bits per second (threshold for the bottom video layer). For example, set as `200000` to have a bottom layer that covers users with low network bandwidth.

* `minHeight` - (Optional) The minimum height of output video layers. For example, set as `360` to avoid output layers of smaller resolutions like 180P.

---

A `transportStream` block supports the following:

* `filenamePattern` - (Required) The file naming pattern used for the creation of output files. The following macros are supported in the file name: `{basename}` - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. `{extension}` - The appropriate extension for this format. `{label}` - The label assigned to the codec/layer. `{index}` - A unique index for thumbnails. Only applicable to thumbnails. `{audioStream}` - string "Audio" plus audio stream number(start from 1). `{bitrate}` - The audio/video bitrate in kbps. Not applicable to thumbnails. `{codec}` - The type of the audio/video codec. `{resolution}` - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename.

* `outputFile` - (Optional) One or more `outputFile` blocks as defined above.

---

An `video` block supports the following:

* `inputLabel` - (Required) The label of the job input which is to be used as an overlay. The input must specify exact one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file.

* `audioGainLevel` - (Optional) The gain level of audio in the overlay. The value should be in range between `0` to `10`. The default is `10`.

* `cropRectangle` - (Optional) A `cropRectangle` block as defined above.

* `end` - (Optional) The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, `pt30S` to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration.

* `fadeInDuration` - (Optional) The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as `pt0S`).

* `fadeOutDuration` - (Optional) The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as `pt0S`).

* `opacity` - (Optional) The opacity of the overlay. The value should be in the range between `0` to `10`. Default to `10`, which means the overlay is opaque.

* `position` - (Optional) A `position` block as defined above.

* `start` - (Optional) The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, `pt05S` to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video.

---

A `videoAnalyzerPreset` block supports the following:

* `audioLanguage` - (Optional) The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode:Basic, since automatic language detection is not included in basic mode. If the language isn't specified, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernible speech. If automatic detection fails to find the language, transcription would fall back to `enUs`. The list of supported languages is available here: <https://go.microsoft.com/fwlink/?linkid=2109463>. 

* `audioAnalysisMode` - (Optional) Possible values are `basic` or `standard`. Determines the set of audio analysis operations to be performed. Default to `standard`.

* `experimentalOptions` - (Optional) Dictionary containing key value pairs for parameters not exposed in the preset itself.
 
* `insightsType` - (Optional) Defines the type of insights that you want the service to generate. The allowed values are `audioInsightsOnly`, `videoInsightsOnly`, and `allInsights`. If you set this to `allInsights` and the input is audio only, then only audio insights are generated. Similarly, if the input is video only, then only video insights are generated. It is recommended that you not use `audioInsightsOnly` if you expect some of your inputs to be video only; or use `videoInsightsOnly` if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out. Default to `allInsights`.

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The ID of the Transform.

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Transform.
* `read` - (Defaults to 5 minutes) Used when retrieving the Transform.
* `update` - (Defaults to 30 minutes) Used when updating the Transform.
* `delete` - (Defaults to 30 minutes) Used when deleting the Transform.

## Import

Transforms can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_media_transform.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.Media/mediaServices/media1/transforms/transform1
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-e1f05056b32ce8c0f07f5456b258a68fea618c78aa22eb076d9748e35451b4be -->