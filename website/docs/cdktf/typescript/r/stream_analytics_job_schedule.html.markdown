---
subcategory: "Stream Analytics"
layout: "azurerm"
page_title: "Azure Resource Manager: azurerm_stream_analytics_job_schedule"
description: |-
  Manages a Stream Analytics Job Schedule.
---


<!-- Please do not edit this file, it is generated. -->
# azurerm_stream_analytics_job_schedule

Manages a Stream Analytics Job Schedule.

## Example Usage

```typescript
import * as constructs from "constructs";
import * as cdktf from "cdktf";
/*Provider bindings are generated by running cdktf get.
See https://cdk.tf/provider-generation for more details.*/
import * as azurerm from "./.gen/providers/azurerm";
class MyConvertedCode extends cdktf.TerraformStack {
  constructor(scope: constructs.Construct, name: string) {
    super(scope, name);
    const azurermResourceGroupExample = new azurerm.resourceGroup.ResourceGroup(
      this,
      "example",
      {
        location: "West Europe",
        name: "example-resources",
      }
    );
    const azurermStorageAccountExample =
      new azurerm.storageAccount.StorageAccount(this, "example_1", {
        accountReplicationType: "LRS",
        accountTier: "Standard",
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "example",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStorageAccountExample.overrideLogicalId("example");
    const azurermStorageContainerExample =
      new azurerm.storageContainer.StorageContainer(this, "example_2", {
        containerAccessType: "private",
        name: "example",
        storageAccountName: cdktf.Token.asString(
          azurermStorageAccountExample.name
        ),
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStorageContainerExample.overrideLogicalId("example");
    const azurermStreamAnalyticsJobExample =
      new azurerm.streamAnalyticsJob.StreamAnalyticsJob(this, "example_3", {
        compatibilityLevel: "1.2",
        dataLocale: "en-GB",
        eventsLateArrivalMaxDelayInSeconds: 60,
        eventsOutOfOrderMaxDelayInSeconds: 50,
        eventsOutOfOrderPolicy: "Adjust",
        location: cdktf.Token.asString(azurermResourceGroupExample.location),
        name: "example-job",
        outputErrorPolicy: "Drop",
        resourceGroupName: cdktf.Token.asString(
          azurermResourceGroupExample.name
        ),
        streamingUnits: 3,
        tags: {
          environment: "Example",
        },
        transformationQuery:
          "    SELECT *\n    INTO [exampleoutput]\n    FROM [exampleinput]\n",
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStreamAnalyticsJobExample.overrideLogicalId("example");
    const azurermStreamAnalyticsOutputBlobExample =
      new azurerm.streamAnalyticsOutputBlob.StreamAnalyticsOutputBlob(
        this,
        "example_4",
        {
          dateFormat: "yyyy-MM-dd",
          name: "exampleoutput",
          pathPattern: "example-{date}-{time}",
          resourceGroupName: cdktf.Token.asString(
            azurermStreamAnalyticsJobExample.resourceGroupName
          ),
          serialization: {
            type: "Avro",
          },
          storageAccountKey: cdktf.Token.asString(
            azurermStorageAccountExample.primaryAccessKey
          ),
          storageAccountName: cdktf.Token.asString(
            azurermStorageAccountExample.name
          ),
          storageContainerName: cdktf.Token.asString(
            azurermStorageContainerExample.name
          ),
          streamAnalyticsJobName: cdktf.Token.asString(
            azurermStreamAnalyticsJobExample.name
          ),
          timeFormat: "HH",
        }
      );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStreamAnalyticsOutputBlobExample.overrideLogicalId("example");
    const azurermStreamAnalyticsStreamInputBlobExample =
      new azurerm.streamAnalyticsStreamInputBlob.StreamAnalyticsStreamInputBlob(
        this,
        "example_5",
        {
          dateFormat: "yyyy/MM/dd",
          name: "exampleinput",
          pathPattern: "",
          resourceGroupName: cdktf.Token.asString(
            azurermStreamAnalyticsJobExample.resourceGroupName
          ),
          serialization: {
            encoding: "UTF8",
            fieldDelimiter: ",",
            type: "Csv",
          },
          storageAccountKey: cdktf.Token.asString(
            azurermStorageAccountExample.primaryAccessKey
          ),
          storageAccountName: cdktf.Token.asString(
            azurermStorageAccountExample.name
          ),
          storageContainerName: cdktf.Token.asString(
            azurermStorageContainerExample.name
          ),
          streamAnalyticsJobName: cdktf.Token.asString(
            azurermStreamAnalyticsJobExample.name
          ),
          timeFormat: "HH",
        }
      );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStreamAnalyticsStreamInputBlobExample.overrideLogicalId("example");
    const azurermStorageBlobExample = new azurerm.storageBlob.StorageBlob(
      this,
      "example_6",
      {
        name: "example",
        source: "example.csv",
        storageAccountName: cdktf.Token.asString(
          azurermStorageAccountExample.name
        ),
        storageContainerName: cdktf.Token.asString(
          azurermStorageContainerExample.name
        ),
        type: "Block",
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStorageBlobExample.overrideLogicalId("example");
    const azurermStreamAnalyticsJobScheduleExample =
      new azurerm.streamAnalyticsJobSchedule.StreamAnalyticsJobSchedule(
        this,
        "example_7",
        {
          dependsOn: [
            azurermStreamAnalyticsJobExample,
            azurermStreamAnalyticsStreamInputBlobExample,
            azurermStreamAnalyticsOutputBlobExample,
          ],
          startMode: "CustomTime",
          startTime: "2022-09-21T00:00:00Z",
          streamAnalyticsJobId: cdktf.Token.asString(
            azurermStreamAnalyticsJobExample.id
          ),
        }
      );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    azurermStreamAnalyticsJobScheduleExample.overrideLogicalId("example");
  }
}

```

## Argument Reference

The following arguments are supported:

* `streamAnalyticsJobId` - (Required) The ID of the Stream Analytics Job that should be scheduled or started. Changing this forces a new resource to be created.

* `startMode` - (Required) The starting mode of the Stream Analytics Job. Possible values are `jobStartTime`, `customTime` and `lastOutputEventTime`.

-> **Note:** Setting `startMode` to `lastOutputEventTime` is only possible if the job had been previously started and produced output.

* `startTime` - (Optional) The time in ISO8601 format at which the Stream Analytics Job should be started e.g. `20220401T00:00:00Z`. This property can only be specified if `startMode` is set to `customTime`

## Attributes Reference

In addition to the Arguments listed above - the following Attributes are exported:

* `id` - The ID of the Stream Analytics Job.

* `lastOutputTime` - The time at which the Stream Analytics job last produced an output.

---

## Timeouts

The `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:

* `create` - (Defaults to 30 minutes) Used when creating the Stream Analytics Job.
* `update` - (Defaults to 30 minutes) Used when updating the Stream Analytics Job.
* `read` - (Defaults to 5 minutes) Used when retrieving the Stream Analytics Job.
* `delete` - (Defaults to 30 minutes) Used when deleting the Stream Analytics Job.

## Import

Stream Analytics Job's can be imported using the `resource id`, e.g.

```shell
terraform import azurerm_stream_analytics_job_schedule.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1/providers/Microsoft.StreamAnalytics/streamingJobs/job1/schedule/default
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-55138763c2ab0038c2e05ccd39891d5da895c0ae03d0ae4c6d96e592ed18ad2e -->